Задача: научится по нескольким предыдущим словам текста "Дом который построил Джек" предсказывать следующее

Решение: рассмторим это как задачу классификации, где классы - слова из текста. Слова кодируем с помощью One Hot Encode. Контекст - сумма One Hot представлений слов, соседствующих с искомым.
Позволим нейросети найти неизвестную зависимость слов от контекста. Ошибку классификации оцениваем Перекрестной энтропией. Веса подбираем методом обратного распространения ошибки.
Тренируем несколько нейросетей по разным контекстам(варьируем число слов до искомого и после). По функции потерь оцениваем какая сеть дает лучший результат, а также находим лучшую из тех, что смотрит только на предыдущие слова.
Приложенный график показывает процесс обучения лучшей из найденных сетей.
