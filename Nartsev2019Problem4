Задача: научится по нескольким предыдущим словам текста "Дом который построил Джек" предсказывать следующее
Решение: рассмотрим это как задачу классификации, где классы - слова из текста. Слова кодируем с помощью One Hot Encode. Контекст - сумма One Hot представлений слов, соседствующих с искомым.
Позволим нейросети найти неизвестную зависимость слов от контекста. Ошибку классификации оцениваем Перекрестной энтропией. Веса подбираем методом обратного распространения ошибки. 
Тренируем несколько нейросетей по разным контекстам(варьируем число слов до искомого и после). По функции потерь оцениваем какая сеть дает лучший результат, а также находим лучшую из тех, что смотрит только на предыдущие слова. 
Приложенный график показывает процесс обучения лучшей из найденных сетей.
